{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itc202/praktik/blob/main/ProtoNet_%D0%BD%D0%B0_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "оригинальная модель Protonet предложена в статье Prototypical Networks for Few-shot Learning появилась на arhiv.org в 2017\n",
        "Одно из улучшений в статье 2023 https://www.sciencedirect.com/science/article/abs/pii/S0167865523001940 (имеется pdf версия) , в статье Plant disease recognition in a low data scenario using few-shot learning от 2024 https://www.sciencedirect.com/science/article/pii/S0168169924002035  и других статьях.\n"
      ],
      "metadata": {
        "id": "4nZlGPO4JTvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Прототипические сети Protonet используются для задач классификации, особенно в контексте обучения с малым количеством примеров.** Они работают, вычисляя прототипы классов и классифицируя новые примеры на основе расстояния до этих прототипов. Вот пример реализации прототипической сети на Keras:"
      ],
      "metadata": {
        "id": "naRTA1N-FYR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом примере мы будем использовать набор данных CIFAR-10, который можно загрузить непосредственно из Keras. Мы будем обучать прототипическую сеть, используя изображения из этого набора данных.\n",
        "python\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4vC8G9-oDl3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как это работает:\n",
        "Метод call:\n",
        "Когда вы передаете изображения в модель, они сначала обрабатываются с помощью слоя Flatten, который преобразует 3D-изображения (например, 32x32x3 для CIFAR-10) в 1D-векторы.\n",
        "\n",
        "Затем эти векторы передаются в плотный слой (Dense), который применяет линейное преобразование с активацией ReLU. Этот слой фактически и **извлекает признаки изображений**, создавая эмбеддинги, которые представляют собой высокоуровневые характеристики изображений.\n",
        "\n",
        "Эмбеддинги:\n",
        "Эмбеддинги, полученные из метода call, используются для дальнейших вычислений, таких как определение прототипов классов и расстояний между эмбеддингами и прототипами.\n",
        "\n",
        "Таким образом, именно в методе call происходит извлечение признаков изображений CIFAR-10 с помощью плотного слоя, который обучается в процессе тренировки модели."
      ],
      "metadata": {
        "id": "T-B_JJiSGWLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В варианте кода ниже нет сверточных слоев. Более сллоожный вариант с кодировщиком на свреточных слоях рпиведен в конце ноутбука\n",
        "Объяснение:\n",
        "Архитектура: **В оригинальной реализации прототипических сетей**, как правило, используется свёрточная нейронная сеть (CNN) в качестве кодировщика для извлечения высокоуровневых признаков из изображений. Это позволяет модели эффективно обрабатывать визуальные данные, учитывая пространственные зависимости и иерархию признаков.\n",
        "\n",
        "Преимущества свёрточных слоёв: Свёрточные слои хорошо подходят для задач компьютерного зрения, так как они могут выявлять локальные паттерны и структуры в изображениях, что значительно улучшает качество извлечения признаков по сравнению с простыми плотными слоями.\n",
        "\n",
        "Таким образом, в отличие от упрощенной версии прототипической сети, представленной в этом  коде, оригинальная модель использует свёрточные слои для более эффективного извлечения признаков из изображений."
      ],
      "metadata": {
        "id": "7IW4bRtfG2po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "KBZh8xBsDstF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrototypicalNetwork(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, num_classes):\n",
        "        super(PrototypicalNetwork, self).__init__()\n",
        "        self.embedding = layers.Flatten()\n",
        "        self.dense = layers.Dense(embedding_dim, activation='relu')\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Получаем эмбеддинги\n",
        "        embeddings = self.dense(self.embedding(inputs))\n",
        "        return embeddings\n",
        "\n",
        "    def compute_prototypes(self, embeddings, labels):\n",
        "        # Вычисляем прототипы для каждого класса\n",
        "        prototypes = []\n",
        "        for i in range(self.num_classes):\n",
        "            class_embeddings = embeddings[labels == i]\n",
        "            if len(class_embeddings) > 0:\n",
        "                prototype = tf.reduce_mean(class_embeddings, axis=0)\n",
        "                prototypes.append(prototype)\n",
        "        return tf.stack(prototypes)\n",
        "\n",
        "    def compute_distances(self, embeddings, prototypes):\n",
        "        # Вычисляем расстояния между эмбеддингами и прототипами\n",
        "        distances = tf.norm(tf.expand_dims(embeddings, 1) - prototypes, axis=2)\n",
        "        return distances"
      ],
      "metadata": {
        "id": "i4-bbF4RDtvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_prototypical_network(train_data, train_labels, embedding_dim=64, num_classes=10, epochs=10, batch_size=32):\n",
        "    model = PrototypicalNetwork(embedding_dim, num_classes)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, len(train_data), batch_size):\n",
        "            batch_data = train_data[i:i + batch_size]\n",
        "            batch_labels = train_labels[i:i + batch_size]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Получаем эмбеддинги\n",
        "                embeddings = model(batch_data)\n",
        "                # Вычисляем прототипы\n",
        "                prototypes = model.compute_prototypes(embeddings, batch_labels)\n",
        "                # Вычисляем расстояния\n",
        "                distances = model.compute_distances(embeddings, prototypes)\n",
        "                # Получаем потери\n",
        "                loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=-distances, labels=batch_labels))\n",
        "\n",
        "            # Обновляем веса\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.numpy()}')"
      ],
      "metadata": {
        "id": "_xEwda0-DxIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем данные CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0  # Нормализация\n",
        "x_test = x_test.astype('float32') / 255.0  # Нормализация\n",
        "y_train = y_train.flatten()  # Преобразуем в одномерный массив\n",
        "y_test = y_test.flatten()  # Преобразуем в одномерный массив"
      ],
      "metadata": {
        "id": "Z2KGvK_oD1Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "train_prototypical_network(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "id": "0h8ivmtSD7aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объяснение изменений\n",
        "Загрузка CIFAR-10: Мы используем cifar10.load_data() для загрузки набора данных CIFAR-10 напрямую из Keras. Данные нормализуются для лучшей работы модели.\n",
        "Модель PrototypicalNetwork: Мы изменили архитектуру модели, чтобы она использовала Flatten для обработки изображений размером 32x32x3 из CIFAR-10. Затем добавляется плотный слой для получения эмбеддингов.\n",
        "Обучение: Обучение происходит поэтапно с использованием батчей, что позволяет эффективно обрабатывать данные.\n",
        "Этот код создает и обучает прототипическую сеть на наборе данных CIFAR-10, используя изображения и метки, доступные в Keras. Вы можете адаптировать параметры, такие как размер эмбеддинга, количество эпох и размер батча, в зависимости от ваших потребностей."
      ],
      "metadata": {
        "id": "32eamcYKD-19"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FSIaAm4iD_35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для загрузки и предобработки пользовательских изображений\n",
        "def load_and_preprocess_image(image_path, target_size=(32, 32)):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize(target_size)  # Изменяем размер\n",
        "    img_array = np.array(img) / 255.0  # Нормализация\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Добавляем размерность для батча\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "U-T55O8REgHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для классификации пользовательских изображений\n",
        "def classify_custom_images(model, image_paths, num_classes):\n",
        "    embeddings = []\n",
        "    for img_path in image_paths:\n",
        "        img_array = load_and_preprocess_image(img_path)\n",
        "        embedding = model(img_array)  # Получаем эмбеддинг\n",
        "        embeddings.append(embedding)\n",
        "\n",
        "    embeddings = tf.concat(embeddings, axis=0)\n",
        "    prototypes = model.compute_prototypes(embeddings, np.zeros(len(embeddings)))  # Используем нулевые метки для прототипов\n",
        "    distances = model.compute_distances(embeddings, prototypes)\n",
        "\n",
        "    # Получаем предсказанные классы\n",
        "    predictions = tf.argmin(distances, axis=1)\n",
        "    return predictions.numpy()\n"
      ],
      "metadata": {
        "id": "1y2qVtrZEjGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования для классификации пользовательских изображений\n",
        "custom_image_paths = ['path_to_your_image1.jpg', 'path_to_your_image2.jpg']  # Замените на свои пути к изображениям\n",
        "predicted_classes = classify_custom_images(model, custom_image_paths, num_classes=10)\n",
        "\n",
        "for img_path, pred_class in zip(custom_image_paths, predicted_classes):\n",
        "    print(f'Image: {img_path}, Predicted Class: {pred_class}')"
      ],
      "metadata": {
        "id": "eVk0RyCqEuE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ниже весь код, предложенный GPT на заапрос с класссифкацией своих изображений"
      ],
      "metadata": {
        "id": "CbojiloQEyAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "class PrototypicalNetwork(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, num_classes):\n",
        "        super(PrototypicalNetwork, self).__init__()\n",
        "        self.embedding = layers.Flatten()\n",
        "        self.dense = layers.Dense(embedding_dim, activation='relu')\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Получаем эмбеддинги\n",
        "        embeddings = self.dense(self.embedding(inputs))\n",
        "        return embeddings\n",
        "\n",
        "    def compute_prototypes(self, embeddings, labels):\n",
        "        # Вычисляем прототипы для каждого класса\n",
        "        prototypes = []\n",
        "        for i in range(self.num_classes):\n",
        "            class_embeddings = embeddings[labels == i]\n",
        "            if len(class_embeddings) > 0:\n",
        "                prototype = tf.reduce_mean(class_embeddings, axis=0)\n",
        "                prototypes.append(prototype)\n",
        "        return tf.stack(prototypes)\n",
        "\n",
        "    def compute_distances(self, embeddings, prototypes):\n",
        "        # Вычисляем расстояния между эмбеддингами и прототипами\n",
        "        distances = tf.norm(tf.expand_dims(embeddings, 1) - prototypes, axis=2)\n",
        "        return distances\n",
        "\n",
        "def train_prototypical_network(train_data, train_labels, embedding_dim=64, num_classes=10, epochs=10, batch_size=32):\n",
        "    model = PrototypicalNetwork(embedding_dim, num_classes)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, len(train_data), batch_size):\n",
        "            batch_data = train_data[i:i + batch_size]\n",
        "            batch_labels = train_labels[i:i + batch_size]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Получаем эмбеддинги\n",
        "                embeddings = model(batch_data)\n",
        "                # Вычисляем прототипы\n",
        "                prototypes = model.compute_prototypes(embeddings, batch_labels)\n",
        "                # Вычисляем расстояния\n",
        "                distances = model.compute_distances(embeddings, prototypes)\n",
        "                # Получаем потери\n",
        "                loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=-distances, labels=batch_labels))\n",
        "\n",
        "            # Обновляем веса\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.numpy()}')\n",
        "\n",
        "# Загружаем данные CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0  # Нормализация\n",
        "x_test = x_test.astype('float32') / 255.0  # Нормализация\n",
        "y_train = y_train.flatten()  # Преобразуем в одномерный массив\n",
        "y_test = y_test.flatten()  # Преобразуем в одномерный массив\n",
        "\n",
        "# Обучение модели\n",
        "train_prototypical_network(x_train, y_train, epochs=10)\n",
        "\n",
        "# Функция для загрузки и предобработки пользовательских изображений\n",
        "def load_and_preprocess_image(image_path, target_size=(32, 32)):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize(target_size)  # Изменяем размер\n",
        "    img_array = np.array(img) / 255.0  # Нормализация\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Добавляем размерность для батча\n",
        "    return img_array\n",
        "\n",
        "# Функция для классификации пользовательских изображений\n",
        "def classify_custom_images(model, image_paths, num_classes):\n",
        "    embeddings = []\n",
        "    for img_path in image_paths:\n",
        "        img_array = load_and_preprocess_image(img_path)\n",
        "        embedding = model(img_array)  # Получаем эмбеддинг\n",
        "        embeddings.append(embedding)\n",
        "\n",
        "    embeddings = tf.concat(embeddings, axis=0)\n",
        "    prototypes = model.compute_prototypes(embeddings, np.zeros(len(embeddings)))  # Используем нулевые метки для прототипов\n",
        "    distances = model.compute_distances(embeddings, prototypes)\n",
        "\n",
        "    # Получаем предсказанные классы\n",
        "    predictions = tf.argmin(distances, axis=1)\n",
        "    return predictions.numpy()\n",
        "\n",
        "# Пример использования для классификации пользовательских изображений\n",
        "custom_image_paths = ['path_to_your_image1.jpg', 'path_to_your_image2.jpg']  # Замените на свои пути к изображениям\n",
        "predicted_classes = classify_custom_images(model, custom_image_paths, num_classes=10)\n",
        "\n",
        "for img_path, pred_class in zip(custom_image_paths, predicted_classes):\n",
        "    print(f'Image: {img_path}, Predicted Class: {pred_class}')"
      ],
      "metadata": {
        "id": "i9sXdyJEE5Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объяснение добавленных частей\n",
        "Функция load_and_preprocess_image: Эта функция загружает изображение, изменяет его размер до 32x32 пикселей (размер изображений в CIFAR-10) и нормализует его.\n",
        "\n",
        "Функция classify_custom_images: Эта функция принимает список путей к пользовательским изображениям, обрабатывает их, получает эмбеддинги и вычисляет расстояния до прототипов. Затем она возвращает предсказанные классы.\n",
        "\n",
        "Пример использования: В конце кода вы можете указать свои пути к изображениям, которые вы хотите классифицировать. Модель будет возвращать предсказанные классы для каждого изображения.\n",
        "Этот код позволяет вам использовать обученную прототипическую сеть для классификации новых изображений, загружая их из ваших собственных файлов."
      ],
      "metadata": {
        "id": "RUtJ13zbFEXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обновленный код прототипической сети (Prototypical Network) с использованием свёрточных слоёв для извлечения признаков\n",
        "В этом обновлённом коде мы добавим свёрточный кодировщик для извлечения признаков из изображений CIFAR-10. Это позволит модели более эффективно обрабатывать визуальные данные."
      ],
      "metadata": {
        "id": "NEaEAQ4GHcZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "FAd6DH0YHgBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определяем свёрточный кодировщик\n",
        "class ConvEncoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(ConvEncoder, self).__init__()\n",
        "        self.conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')\n",
        "        self.pool1 = layers.MaxPooling2D((2, 2))\n",
        "        self.conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')\n",
        "        self.pool2 = layers.MaxPooling2D((2, 2))\n",
        "        self.conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')\n",
        "        self.pool3 = layers.MaxPooling2D((2, 2))\n",
        "        self.flatten = layers.Flatten()\n",
        "        self.dense = layers.Dense(64, activation='relu')  # Эмбеддинг размерности 64\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.flatten(x)\n",
        "        return self.dense(x)"
      ],
      "metadata": {
        "id": "e8yuDxMDHi5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrototypicalNetwork(tf.keras.Model):\n",
        "    def __init__(self, encoder, num_classes):\n",
        "        super(PrototypicalNetwork, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.encoder(inputs)\n",
        "\n",
        "    def compute_prototypes(self, embeddings, labels):\n",
        "        prototypes = []\n",
        "        for i in range(self.num_classes):\n",
        "            class_embeddings = embeddings[labels == i]\n",
        "            if len(class_embeddings) > 0:\n",
        "                prototype = tf.reduce_mean(class_embeddings, axis=0)\n",
        "                prototypes.append(prototype)\n",
        "        return tf.stack(prototypes)\n",
        "\n",
        "    def compute_distances(self, embeddings, prototypes):\n",
        "        distances = tf.norm(tf.expand_dims(embeddings, 1) - prototypes, axis=2)\n",
        "        return distances"
      ],
      "metadata": {
        "id": "G2uaXShaHmJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_prototypical_network(train_data, train_labels, num_classes=10, epochs=10, batch_size=32):\n",
        "    encoder = ConvEncoder()\n",
        "    model = PrototypicalNetwork(encoder, num_classes)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(0, len(train_data), batch_size):\n",
        "            batch_data = train_data[i:i + batch_size]\n",
        "            batch_labels = train_labels[i:i + batch_size]\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                embeddings = model(batch_data)\n",
        "                prototypes = model.compute_prototypes(embeddings, batch_labels)\n",
        "                distances = model.compute_distances(embeddings, prototypes)\n",
        "                loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=-distances, labels=batch_labels))\n",
        "\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss.numpy()}')"
      ],
      "metadata": {
        "id": "HjKx7pnJHqVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загружаем данные CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255.0  # Нормализация\n",
        "x_test = x_test.astype('float32') / 255.0  # Нормализация\n",
        "y_train = y_train.flatten()  # Преобразуем в одномерный массив\n",
        "y_test = y_test.flatten()  # Преобразуем в одномерный массив\n",
        "\n",
        "# Обучение модели\n",
        "train_prototypical_network(x_train, y_train, epochs=10)\n",
        "\n",
        "# Функция для загрузки и предобработки пользовательских изображений\n",
        "def load_and_preprocess_image(image_path, target_size=(32, 32)):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize(target_size)  # Изменяем размер\n",
        "    img_array = np.array(img) / 255.0  # Нормализация\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Добавляем размерность для батча\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "hqLJr8QHHujm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для классификации пользовательских изображений\n",
        "def classify_custom_images(model, image_paths, num_classes):\n",
        "    encoder = model.encoder  # Получаем кодировщик\n",
        "    embeddings = []\n",
        "    for img_path in image_paths:\n",
        "        img_array = load_and_preprocess_image(img_path)\n",
        "        embedding = encoder(img_array)  # Получаем эмбеддинг\n",
        "        embeddings.append(embedding)\n",
        "\n",
        "    embeddings = tf.concat(embeddings, axis=0)\n",
        "    prototypes = model.compute_prototypes(embeddings, np.zeros(len(embeddings)))  # Используем нулевые метки для прототипов\n",
        "    distances = model.compute_distances(embeddings, prototypes)\n",
        "\n",
        "    # Получаем предсказанные классы\n",
        "    predictions = tf.argmin(distances, axis=1)\n",
        "    return predictions.numpy()"
      ],
      "metadata": {
        "id": "1Fz4Vc3bHx2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования для классификации пользовательских изображений\n",
        "custom_image_paths = ['path_to_your_image1.jpg', 'path_to_your_image2.jpg']  # Замените на свои пути к изображениям\n",
        "predicted_classes = classify_custom_images(model, custom_image_paths, num_classes=10)\n",
        "\n",
        "for img_path, pred_class in zip(custom_image_paths, predicted_classes):\n",
        "    print(f'Image: {img_path}, Predicted Class: {pred_class}')"
      ],
      "metadata": {
        "id": "nMELCwNpH0Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объяснение изменений:\n",
        "Кодировщик ConvEncoder:\n",
        "Добавлен новый класс ConvEncoder, который состоит из свёрточных слоёв и слоёв подвыборки (MaxPooling). Это позволяет модели извлекать более сложные признаки из изображений.\n",
        "\n",
        "В конце кодировщика используется плотный слой для получения окончательных эмбеддингов размерности 64.\n",
        "\n",
        "Изменение в классе PrototypicalNetwork:\n",
        "Теперь класс PrototypicalNetwork принимает экземпляр ConvEncoder в качестве параметра, что позволяет использовать свёрточные слои для извлечения признаков.\n",
        "\n",
        "Обучение и предсказание:\n",
        "\n",
        "В процессе обучения и предсказания мы используем кодировщик для получения эмбеддингов изображений, как и раньше, но теперь с учетом свёрточных слоёв.\n",
        "\n",
        "Функция предсказания:\n",
        "\n",
        "Функция classify_custom_images использует кодировщик для извлечения эмбеддингов из пользовательских изображений перед вычислением прототипов и расстояний.\n",
        "Этот код теперь включает свёрточные слои для извлечения признаков, что должно улучшить качество работы модели на задачах классификации."
      ],
      "metadata": {
        "id": "0A4y6hMLH3Qg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Почему для обучения модели здесь используется своя функция train_prototypical_network, а не станадртный метод fit для класса Model . Можно ли сделать так, чтобы использовать не свою функцию обучения, а этот метод fit?"
      ],
      "metadata": {
        "id": "lkYLUvAMIr16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном коде используется собственная функция train_prototypical_network для обучения модели по нескольким причинам:\n",
        "\n",
        "Специфика задачи: Прототипические сети требуют специфического подхода к обучению, который включает в себя вычисление прототипов для каждого класса и расстояний между эмбеддингами и этими прототипами. Это не является стандартной процедурой, поддерживаемой методом fit().\n",
        "\n",
        "Контроль над процессом обучения: Используя собственную функцию, разработчик имеет полный контроль над процессом обучения, включая управление градиентами, вычисление потерь и обновление весов. Это позволяет более гибко настраивать процесс обучения в соответствии с требованиями модели.\n",
        "\n",
        "Кастомизация: В данной реализации необходимо выполнять специфические операции, такие как вычисление прототипов и расстояний, которые не могут быть легко реализованы с помощью стандартного метода fit()."
      ],
      "metadata": {
        "id": "DG5EnX8QIxVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Можно ли использовать метод fit()?**\n",
        "Да, можно адаптировать код так, чтобы использовать метод fit(). Для этого необходимо переопределить метод **train_step** в классе модели. Это позволит интегрировать специфические операции, такие как вычисление прототипов и расстояний, в стандартный процесс обучения. Вот как это можно сделать:"
      ],
      "metadata": {
        "id": "DJ1By00hI1to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PrototypicalNetwork(tf.keras.Model):\n",
        "    def __init__(self, encoder, num_classes):\n",
        "        super(PrototypicalNetwork, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.encoder(inputs)\n",
        "\n",
        "    def compute_prototypes(self, embeddings, labels):\n",
        "        prototypes = []\n",
        "        for i in range(self.num_classes):\n",
        "            class_embeddings = embeddings[labels == i]\n",
        "            if len(class_embeddings) > 0:\n",
        "                prototype = tf.reduce_mean(class_embeddings, axis=0)\n",
        "                prototypes.append(prototype)\n",
        "        return tf.stack(prototypes)\n",
        "\n",
        "    def compute_distances(self, embeddings, prototypes):\n",
        "        distances = tf.norm(tf.expand_dims(embeddings, 1) - prototypes, axis=2)\n",
        "        return distances\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Разделяем данные на входы и метки\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            embeddings = self(x, training=True)\n",
        "            prototypes = self.compute_prototypes(embeddings, y)\n",
        "            distances = self.compute_distances(embeddings, prototypes)\n",
        "            loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=-distances, labels=y))\n",
        "\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "# Обучение модели с использованием метода fit\n",
        "model = PrototypicalNetwork(ConvEncoder(), num_classes=10)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam())\n",
        "\n",
        "# Теперь можно использовать метод fit\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "k7bhQ7QMI1PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ниже показан пример того, как ранеее оубченная модель Protonet используется дл распознавания   нового класса. Ранее оубченная модель была сохранена в формате h5. Для этого для нового класса также формируется набор примеров, по которым будет вычисляться прототип. Далее этот прототип вклоючается в список уже известных модели прототипов (предполагаем, что они известны из процесса обучения). Видно, что прототип формируется оубченной моделью с помощью perdict\n",
        "\n",
        "ЗДЕСЬ для иллюстрации исопльзуется новый класс \"человек\", а моель обучалась на классах \"кошка\", \"собака\", \"олень\""
      ],
      "metadata": {
        "id": "rWdsthpdRxOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# Загрузка обученной модели\n",
        "model = load_model('path_to_your_protonet_model.h5')\n",
        "\n",
        "# Функция для предобработки изображения\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))  # Измените размер в зависимости от вашей модели\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0  # Нормализация\n",
        "    return img_array\n",
        "\n",
        "# Функция для получения прототипа класса\n",
        "def get_class_prototype(images):\n",
        "    features = []\n",
        "    for img in images:\n",
        "        feature = model.predict(preprocess_image(img))\n",
        "        features.append(feature)\n",
        "    return np.mean(features, axis=0)"
      ],
      "metadata": {
        "id": "1aOBzVFUSYam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Примеры изображений для нового класса \"человек\"\n",
        "human_examples = ['path_to_human_image1.jpg', 'path_to_human_image2.jpg']\n",
        "human_prototype = get_class_prototype(human_examples)\n",
        "\"\"\"\n",
        "# Прототипы существующих классов\n",
        "dog_prototype = ...  # Получите прототип для собак\n",
        "cat_prototype = ...  # Получите прототип для кошек\n",
        "deer_prototype = ...  # Получите прототип для оленей\n",
        "\"\"\"\"\n",
        "# Примеры изображений для ранее известных классов\n",
        "dog_examples = [preprocess_image('path_to_dog_image1.jpg'), preprocess_image('path_to_dog_image2.jpg')]\n",
        "cat_examples = [preprocess_image('path_to_cat_image1.jpg'), preprocess_image('path_to_cat_image2.jpg')]\n",
        "deer_examples = [preprocess_image('path_to_deer_image1.jpg'), preprocess_image('path_to_deer_image2.jpg')]\n",
        "\n",
        "# Получение прототипов классов\n",
        "dog_prototype = get_class_prototypes(dog_examples)\n",
        "cat_prototype = get_class_prototypes(cat_examples)\n",
        "deer_prototype = get_class_prototypes(deer_examples)\n",
        "\n",
        "# Обновление массива прототипов\n",
        "class_prototypes = np.array([dog_prototype, cat_prototype, deer_prototype, human_prototype])"
      ],
      "metadata": {
        "id": "KeazWS-xSwtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для предсказания класса\n",
        "def predict_class(img_path):\n",
        "    img = preprocess_image(img_path)\n",
        "    img_features = model.predict(img)  # Получаем вектор признаков для нового изображения\n",
        "    distances = np.linalg.norm(class_prototypes - img_features, axis=1)  # Вычисляем расстояния до прототипов\n",
        "    predicted_class = np.argmin(distances)  # Находим класс с минимальным расстоянием\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "3dnkIsHKTkEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования\n",
        "test_image_path = 'path_to_test_image.jpg'\n",
        "predicted_class = predict_class(test_image_path)\n",
        "\n",
        "# Интерпретация результата\n",
        "class_names = ['Dog', 'Cat', 'Deer']\n",
        "print(f'The predicted class for the image is: {class_names[predicted_class]}')"
      ],
      "metadata": {
        "id": "5D1zHfjPTm0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}